{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transcriber.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "19VXwqkvH0V3QbE-jhMyqtH5DmAE2D5-K",
      "authorship_tag": "ABX9TyNzhf2IvdGp02lycwEbvEXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/MidiTurmoil/blob/main/Transcriber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYW3887topr9"
      },
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Transcriber <font color=\"#999\" size=\"3\">v0.0.1</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/MidiExperiments\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font size=\"3\" color=\"#999\"><a href=\"https://inha.se\" target=\"_blank\"><font color=\"#999\">O. Inha</font></a></font></font>\n",
        "\n",
        "Transcriber takes an audio file or a youtube link, separates it into stems using Deezer Spleeter, then transcribes the track or selected stem to MIDI notation using Google Magenta's Onsets and Frames Piano Transcription. Decent accuracy is reached only with piano."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG11l0A5G4Y_",
        "cellView": "form"
      },
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisities.\n",
        "\n",
        "force_setup = False\n",
        "pip_packages = 'youtube-dl magenta spleeter mido pychord pyfluidsynth midi2audio musthe midiutil'\n",
        "apt_packages = 'fluidsynth sox'\n",
        "\n",
        "import os\n",
        "from google.colab import drive, output\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') or force_setup == True:\n",
        "  %cd /content/\n",
        "  !apt-get install {apt_packages}\n",
        "  output.clear()\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  output.clear()\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/MIDIGenerators/main/roll.py\n",
        "  !gsutil -q -m cp -R gs://neural-research/olaviinha/spleeter-configs/custom-5stems-22kHz-z.json /content/cfg.json\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if not os.path.isdir('/content/drive') and force_setup == False:\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "# Drive symlink\n",
        "if not os.path.isdir('/content/mydrive') and force_setup == False:\n",
        "  os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "  drive_root_set = True\n",
        "drive_root = '/content/mydrive/'\n",
        "\n",
        "tmp = '/content/tmp/'\n",
        "osf = tmp+'osf/'\n",
        "splt = tmp+'spleets/'\n",
        "tbe = tmp+'tube/'\n",
        "scribd = tmp+'scribd/'\n",
        "create_dirs([tmp, osf, splt])\n",
        "tmp_dir = tmp\n",
        "\n",
        "whl_installed = False\n",
        "\n",
        "if not os.path.isdir('/content/sf') and force_setup == False:\n",
        "  !gsutil -q -m cp -R gs://neural-research/olaviinha/sf/* {tmp}\n",
        "\n",
        "op(c.title, 'Get checkpoint...\\n')\n",
        "!gsutil -q -m cp -R gs://magentadata/models/onsets_frames_transcription/* {osf}\n",
        "!unzip -o \"{osf}/maestro_checkpoint.zip\" -d \"{osf}\"\n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'Setup finished.')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoSbtAkz3Gwn",
        "cellView": "form"
      },
      "source": [
        "#@markdown #Transcribe\n",
        "\n",
        "#@markdown <small>Input may be a youtube-link or an audio file located in your Google Drive.</small>\n",
        "input = \"https://www.youtube.com/watch?v=oUFJJNQGwhk\" #@param {type:\"string\"}\n",
        "transcribe = 'piano' #@param [\"all_stems\", \"vocals\", \"piano\", \"bass\", \"other\", \"drums\"]\n",
        "\n",
        "#@markdown ##Save transcribed MIDI\n",
        "#@markdown <small>Directory path to Google Drive in which the transcribed MIDI will be saved. If left empty, MIDI file will not be saved to your Drive.</small>\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#----------------------------------------------------------------------------#\n",
        "\n",
        "def fix_path(path, add_slash=False):\n",
        "  if not os.path.isdir(path):\n",
        "    create_dirs([path])\n",
        "  if os.path.isdir(path) and not path.endswith('/'):\n",
        "    path = path+\"/\"\n",
        "  if path.startswith('/') and add_slash == True:\n",
        "    path = path[1:]\n",
        "  return path\n",
        "\n",
        "#----------------------------------------------------------------------------#\n",
        "\n",
        "if output_dir == '':\n",
        "  output_dir = tmp\n",
        "  fixed_output_dir = tmp\n",
        "else:\n",
        "  fixed_output_dir = drive_root+fix_path(output_dir)\n",
        "\n",
        "#----------------------------------------------------------------------------#\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "from glob import glob\n",
        "from shutil import copyfile\n",
        "\n",
        "input_type = check_input_type(input)\n",
        "\n",
        "if input_type == 'unknown':\n",
        "  input = drive_root+fix_path(input)\n",
        "  input_type = check_input_type(input)\n",
        "\n",
        "if input_type == 'youtube':\n",
        "  !rm {tbe}*\n",
        "  !youtube-dl --restrict-filenames -x --no-continue --audio-format wav -o \"{tbe}%(title)s.%(ext)s\" {input}\n",
        "  output.clear()\n",
        "\n",
        "if input_type == 'file':\n",
        "  filename, extension = path.splitext(str(input))\n",
        "\n",
        "if transcribe == 'all_stems':\n",
        "  use_stem = input\n",
        "else:\n",
        "  op(c.title, 'Separate stems...\\n')\n",
        "  from spleeter.separator import Separator\n",
        "  from spleeter.audio.adapter import get_default_audio_adapter\n",
        "  separator = Separator('spleeter:5stems')\n",
        "  file_list = list_audio(tbe)\n",
        "  for audiofile in file_list:\n",
        "    separator.separate_to_file(audiofile, splt)\n",
        "    use_stem = splt+basename(audiofile)+'/'+transcribe+'.wav'\n",
        "\n",
        "# DO\n",
        "\n",
        "CHECKPOINT_DIR = str(osf)+\"train\"\n",
        "\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "  ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "output.clear()\n",
        "op(c.title, 'Transcribe...\\n')\n",
        "!onsets_frames_transcription_transcribe --model_dir=\"{CHECKPOINT_DIR}\" \"{use_stem}\"\n",
        "\n",
        "if output_dir != '':\n",
        "  from shutil import copyfile\n",
        "  scribd_midi = splt+basename(audiofile)+'/'+transcribe+'.wav.midi'\n",
        "  final_output_file = fixed_output_dir+basename(audiofile)+'_'+transcribe+'_'+rnd_str(4)+'.mid'\n",
        "  copyfile(scribd_midi, final_output_file)\n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'Done.\\n\\n')\n",
        "\n",
        "# print(final_output_file)\n",
        "\n",
        "from mido import MidiFile\n",
        "import librosa\n",
        "from midi2audio import FluidSynth\n",
        "from IPython.display import display, Audio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import roll\n",
        "from random import shuffle\n",
        "from musthe import *\n",
        "\n",
        "from mido import MidiFile\n",
        "\n",
        "sf2dir = tmp+'base/'\n",
        "pi = sf2dir+'SalC5Light2.sf2'\n",
        "\n",
        "mid = MidiFile(final_output_file)\n",
        "\n",
        "## Remove very short notes\n",
        "# min_time = 0\n",
        "# new_msgs = [None] * len(mid.tracks)\n",
        "# for i, track in enumerate(mid.tracks):\n",
        "#   new_msgs[i] = []\n",
        "#   for ii, msg in enumerate(track):\n",
        "#     if msg.type == 'note_on' and msg.time < min_time:\n",
        "#       msg.time = 0\n",
        "#       msg.velocity = 0\n",
        "\n",
        "def plot_notation(midifile):\n",
        "  midr = roll.mfplt(midifile)\n",
        "  midr.draw_roll()\n",
        "\n",
        "fname = rnd_str(4)\n",
        "midi_filename = tmp+fname+'.mid'\n",
        "mid.save(midi_filename)\n",
        "audio_preview = tmp+fname+'.wav'\n",
        "FluidSynth(pi).midi_to_audio(midi_filename, audio_preview)\n",
        "plot_notation(midi_filename)\n",
        "test = librosa.load(audio_preview, sr=44100, mono=False)\n",
        "\n",
        "audio_player(test[0])\n",
        "\n",
        "op(c.title, '\\n\\nPath to the generated MIDI file (input for other notebooks):', final_output_file.replace(drive_root,''))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}